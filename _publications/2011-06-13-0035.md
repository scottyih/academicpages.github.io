---
title: "Learning Discriminative Projections for Text Similarity Measures"
collection: publications
permalink: /publication/2011-06-13-0035
abstract: 'Traditional text similarity measures consider
each term similar only to itself and do not
model semantic relatedness of terms. We propose
a novel discriminative training method
that projects the raw term vectors into a common,
low-dimensional vector space. Our approach
operates by finding the optimal matrix
to minimize the loss of the pre-selected similarity
function (e.g., cosine) of the projected
vectors, and is able to efficiently handle a
large number of training examples in the highdimensional
space. Evaluated on two very different
tasks, cross-lingual document retrieval
and ad relevance measure, our method not
only outperforms existing state-of-the-art approaches,
but also achieves high accuracy at
low dimensions and is thus more efficient.'
date: 2011-06-13
author: 'Wen-tau Yih, Kristina Toutanova, John Platt and Chris Meek'
venue: 'CoNLL-2011'
paperurl: '../files/Yih20CoNLL-11.pdf'
biburl: '../publications/2011-06-13-0035.txt'
slides_poster: https://github.com/scottyih/Slides/blob/master/S2Net%20-%20CoNLL-11%20-%20Deck.pptx
award: Best Paper
---

<a href='../files/Yih20CoNLL-11.pdf'>Download paper here</a>

Traditional text similarity measures consider
each term similar only to itself and do not
model semantic relatedness of terms. We propose
a novel discriminative training method
that projects the raw term vectors into a common,
low-dimensional vector space. Our approach
operates by finding the optimal matrix
to minimize the loss of the pre-selected similarity
function (e.g., cosine) of the projected
vectors, and is able to efficiently handle a
large number of training examples in the highdimensional
space. Evaluated on two very different
tasks, cross-lingual document retrieval
and ad relevance measure, our method not
only outperforms existing state-of-the-art approaches,
but also achieves high accuracy at
low dimensions and is thus more efficient.
