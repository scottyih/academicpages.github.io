---
title: "Tracking State Changes in Procedural Text: A Challenge Dataset and Models for Process Paragraph Comprehension"
collection: publications
permalink: /publication/2018-06-02-0066
abstract: 'We present a new dataset and models for comprehending paragraphs about processes (e.g., photosynthesis), an important genre of text describing a dynamic world. The new dataset, ProPara, is the first to contain natural (rather than machine-generated) text about a changing world along with a full annotation of entity states (location and existence) during those changes (81k datapoints). The end-task, tracking the location and existence of entities through the text, is challenging because the causal 
effects of actions are often implicit and need to be inferred. We find that previous models that have worked well on synthetic data achieve only mediocre performance on ProPara, and introduce two new neural models that exploit alternative mechanisms for state prediction, in particular using LSTM input encoding and span prediction. The new models improve accuracy by up to 19%. We are releasing the ProPara dataset and our models to the community.'
date: 2018-06-02
author: 'Bhavana Dalvi, Lifu Huang, Niket Tandon, Wen-tau Yih and Peter Clark'
venue: 'NAACL-HLT-2018'
paperurl: '../files/N18-1144.pdf'
biburl: '../publications/2018-06-02-0066.txt'
dataset: http://data.allenai.org/propara/
code: https://github.com/allenai/propara
---

<a href='../files/N18-1144.pdf'>Download paper here</a>

We present a new dataset and models for comprehending paragraphs about processes (e.g., photosynthesis), an important genre of text describing a dynamic world. The new dataset, ProPara, is the first to contain natural (rather than machine-generated) text about a changing world along with a full annotation of entity states (location and existence) during those changes (81k datapoints). The end-task, tracking the location and existence of entities through the text, is challenging because the causal 
effects of actions are often implicit and need to be inferred. We find that previous models that have worked well on synthetic data achieve only mediocre performance on ProPara, and introduce two new neural models that exploit alternative mechanisms for state prediction, in particular using LSTM input encoding and span prediction. The new models improve accuracy by up to 19%. We are releasing the ProPara dataset and our models to the community.
