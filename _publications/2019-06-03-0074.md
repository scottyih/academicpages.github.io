---
title: "Be Consistent! Improving Procedural Text Comprehension using Label Consistency"
collection: publications
permalink: /publication/2019-06-03-0074
abstract: 'Our goal is procedural text comprehension,
namely tracking how the properties of entities
(e.g., their location) change with time given a
procedural text (e.g., a paragraph about photosynthesis, a recipe). This task is challenging as the world is changing throughout the
text, and despite recent advances, current systems still struggle with this task. Our approach
is to leverage the fact that, for many procedural texts, multiple independent descriptions
are readily available, and that predictions from
them should be consistent (label consistency).
We present a new learning framework that
leverages label consistency during training, allowing consistency bias to be built into the
model. Evaluation on a standard benchmark
dataset for procedural text, ProPara (Dalvi
et al., 2018), shows that our approach significantly improves prediction performance (F1)
over prior state-of-the-art systems.'
date: 2019-06-03
author: 'Xinya Du, Bhavana Dalvi, Niket Tandon, Antoine Bosselut, Wen-tau Yih, Peter Clark and Claire Cardie'
venue: 'NAACL-HLT-2019'
paperurl: '../files/naacl19_ai2_be_consistent.pdf'
biburl: '../publications/2019-06-03-0074.txt'
---

<a href='../files/naacl19_ai2_be_consistent.pdf'>Download paper here</a>

Our goal is procedural text comprehension,
namely tracking how the properties of entities
(e.g., their location) change with time given a
procedural text (e.g., a paragraph about photosynthesis, a recipe). This task is challenging as the world is changing throughout the
text, and despite recent advances, current systems still struggle with this task. Our approach
is to leverage the fact that, for many procedural texts, multiple independent descriptions
are readily available, and that predictions from
them should be consistent (label consistency).
We present a new learning framework that
leverages label consistency during training, allowing consistency bias to be built into the
model. Evaluation on a standard benchmark
dataset for procedural text, ProPara (Dalvi
et al., 2018), shows that our approach significantly improves prediction performance (F1)
over prior state-of-the-art systems.
