---
title: "Learning from Explicit and Implicit Supervision Jointly for Algebra Word Problems"
collection: publications
permalink: /publication/2016-11-01-0060
abstract: 'Automatically solving algebra word problems
has raised considerable interest recently. Existing
state-of-the-art approaches mainly rely
on learning from human annotated equations.
In this paper, we demonstrate that it is possible
to efficiently mine algebra problems and
their numerical solutions with little to no manual
effort. To leverage the mined dataset, we
propose a novel structured-output learning algorithm
that aims to learn from both explicit
(e.g., equations) and implicit (e.g., solutions)
supervision signals jointly. Enabled by this
new algorithm, our model gains 4.6% absolute
improvement in accuracy on the ALG514
benchmark compared to the one without
using implicit supervision. The final model
also outperforms the current state-of-the-art
approach by 3%.'
date: 2016-11-01
author: 'Shyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang and Wen-tau Yih'
venue: 'EMNLP-2016'
paperurl: '../files/D16-1029.pdf'
biburl: '../publications/2016-11-01-0060.txt'
video: https://vimeo.com/239246573
---

<a href='../files/D16-1029.pdf'>Download paper here</a>

Automatically solving algebra word problems
has raised considerable interest recently. Existing
state-of-the-art approaches mainly rely
on learning from human annotated equations.
In this paper, we demonstrate that it is possible
to efficiently mine algebra problems and
their numerical solutions with little to no manual
effort. To leverage the mined dataset, we
propose a novel structured-output learning algorithm
that aims to learn from both explicit
(e.g., equations) and implicit (e.g., solutions)
supervision signals jointly. Enabled by this
new algorithm, our model gains 4.6% absolute
improvement in accuracy on the ALG514
benchmark compared to the one without
using implicit supervision. The final model
also outperforms the current state-of-the-art
approach by 3%.
