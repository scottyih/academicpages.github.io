---
title: "Reasoning about Actions and State Changes by Injecting Commonsense Knowledge"
collection: publications
permalink: /publication/2018-10-31-0069
abstract: 'Comprehending procedural text, e.g., a paragraph
describing photosynthesis, requires
modeling actions and the state changes they
produce, so that questions about entities at different
timepoints can be answered. Although
several recent systems have shown impressive
progress in this task, their predictions can be
globally inconsistent or highly improbable. In
this paper, we show how the predicted effects
of actions in the context of a paragraph can
be improved in two ways: (1) by incorporating
global, commonsense constraints (e.g., a
non-existent entity cannot be destroyed), and
(2) by biasing reading with preferences from
large-scale corpora (e.g., trees rarely move).
Unlike earlier methods, we treat the problem
as a neural structured prediction task, allowing
hard and soft constraints to steer the model
away from unlikely predictions. We show that
the new model significantly outperforms earlier
systems on a benchmark dataset for procedural
text comprehension (+8% relative gain),
and that it also avoids some of the nonsensical
predictions that earlier systems make.'
date: 2018-10-31
author: 'Niket Tandon, Bhavana Dalvi, Joel Grus, Wen-tau Yih, Antoine Bosselut and Peter Clark'
venue: 'EMNLP-2018'
paperurl: '../files/paper-1172.pdf'
biburl: '../publications/2018-10-31-0069.txt'
---

<a href='../files/paper-1172.pdf'>Download paper here</a>

Comprehending procedural text, e.g., a paragraph
describing photosynthesis, requires
modeling actions and the state changes they
produce, so that questions about entities at different
timepoints can be answered. Although
several recent systems have shown impressive
progress in this task, their predictions can be
globally inconsistent or highly improbable. In
this paper, we show how the predicted effects
of actions in the context of a paragraph can
be improved in two ways: (1) by incorporating
global, commonsense constraints (e.g., a
non-existent entity cannot be destroyed), and
(2) by biasing reading with preferences from
large-scale corpora (e.g., trees rarely move).
Unlike earlier methods, we treat the problem
as a neural structured prediction task, allowing
hard and soft constraints to steer the model
away from unlikely predictions. We show that
the new model significantly outperforms earlier
systems on a benchmark dataset for procedural
text comprehension (+8% relative gain),
and that it also avoids some of the nonsensical
predictions that earlier systems make.
